{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f362c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric as tg\n",
    "import torch_scatter\n",
    "import e3nn\n",
    "from typing import Dict, Union\n",
    "\n",
    "# crystal structure data\n",
    "from ase import Atom, Atoms\n",
    "from ase.neighborlist import neighbor_list\n",
    "from ase.visualize.plot import plot_atoms\n",
    "\n",
    "# data pre-processing and visualization\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "# utilities\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from utils.utils_data import (load_data, train_valid_test_split, plot_example, plot_predictions, plot_partials,\n",
    "                              palette, colors, cmap)\n",
    "from utils.utils_model import SimpleNetwork, visualize_layers, train\n",
    "from utils.utils_plot import plotly_surface, plot_orbitals, get_middle_feats\n",
    "\n",
    "bar_format = '{l_bar}{bar:10}{r_bar}{bar:-10b}'\n",
    "default_dtype = torch.float64\n",
    "torch.set_default_dtype(default_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3798ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload a module without kernel restart\n",
    "from importlib import reload\n",
    "import sys\n",
    "reload(sys.modules['utils.utils_data'])\n",
    "reload(sys.modules['utils.utils_model'])\n",
    "from utils.utils_model import SimpleNetwork, visualize_layers, train\n",
    "from utils.utils_data import (load_data, train_valid_test_split, cmap, colors, plot_example, plot_predictions,\n",
    "                              plot_partials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4069f4",
   "metadata": {},
   "source": [
    "### Data provenance\n",
    "We train our model using the database of Density Functional Perturbation Theory (DFPT)-calculated phonon densities of states (DoS), containing approximately 1,500 crystalline solids [[Petretto et al. 2018]](https://doi.org/10.1038/sdata.2018.65)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020da470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df, species = load_data('data/data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84fe4f9",
   "metadata": {},
   "source": [
    "### Data structures\n",
    "Crystal structures are represented as [ASE](https://wiki.fysik.dtu.dk/ase/ase/atoms.html?highlight=atoms#the-atoms-object) (Atomic Simulation Environment) `Atoms` objects, which store the atomic species and positions of each atom in the unit cell, as well as the lattice vectors of the unit cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfe78e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot an example structure\n",
    "i = 12 # structure index in dataframe\n",
    "\n",
    "struct = df.iloc[i]['structure']\n",
    "symbols = np.unique(list(struct.symbols))\n",
    "z = dict(zip(symbols, range(len(symbols))))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "norm = plt.Normalize(vmin=0, vmax=len(symbols)-1)\n",
    "color = [mpl.colors.to_hex(k) for k in cmap(norm([z[j] for j in list(struct.symbols)]))]\n",
    "plot_atoms(struct, ax, radii=0.25, colors=color, rotation=('0x,90y,0z'))\n",
    "\n",
    "ax.set_xlabel(r'$x_1\\ (\\AA)$')\n",
    "ax.set_ylabel(r'$x_2\\ (\\AA)$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae3b60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lattice parameter statistics\n",
    "def get_lattice_parameters(df):\n",
    "    a = []\n",
    "    for entry in df.itertuples():\n",
    "        a.append(entry.structure.cell.cellpar()[:3])\n",
    "    return np.stack(a)\n",
    "\n",
    "a = get_lattice_parameters(df)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(5,4))\n",
    "b = 0.\n",
    "bins = 50\n",
    "for d, c, n in zip(['a', 'b', 'c'], colors.values(), [a[:,0], a[:,1], a[:,2]]):\n",
    "    color = [int(c.lstrip('#')[i:i+2], 16)/255. for i in (0,2,4)]\n",
    "    y, bins, _, = ax.hist(n, bins=bins, fc=color+[0.7], ec=color, bottom=b, label=d)\n",
    "    b += y\n",
    "ax.set_xlabel('lattice parameter')\n",
    "ax.set_ylabel('number of examples')\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "print('average lattice parameter (a/b/c):', a[:,0].mean(), '/', a[:,1].mean(), '/', a[:,2].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c354b9",
   "metadata": {},
   "source": [
    "### Feature representation\n",
    "Each atom is associated with a feature vector that one-hot encodes its atomic mass in the index corresponding to its atomic number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f3027d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding atomic mass\n",
    "type_encoding = {}\n",
    "specie_am = []\n",
    "for Z in tqdm(range(1, 119), bar_format=bar_format):\n",
    "    specie = Atom(Z)\n",
    "    type_encoding[specie.symbol] = Z\n",
    "    specie_am.append(specie.mass)\n",
    "\n",
    "type_onehot = torch.diag(torch.tensor(specie_am))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5bfd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build data\n",
    "def build_data(entry, type_encoding, type_onehot, r_max=5.):\n",
    "    symbols = list(entry.structure.symbols).copy()\n",
    "    positions = torch.from_numpy(entry.structure.positions.copy())\n",
    "    lattice = torch.from_numpy(entry.structure.cell.array.copy()).unsqueeze(0)\n",
    "\n",
    "    # edge_src and edge_dst are the indices of the central and neighboring atom, respectively\n",
    "    # edge_shift indicates whether the neighbors are in different images or copies of the unit cell\n",
    "    edge_src, edge_dst, edge_shift = neighbor_list(\"ijS\", a=entry.structure, cutoff=r_max/2., self_interaction=True)\n",
    "    \n",
    "    # compute the relative distances and unit cell shifts from periodic boundaries\n",
    "    edge_batch = positions.new_zeros(positions.shape[0], dtype=torch.long)[torch.from_numpy(edge_src)]\n",
    "    edge_vec = (positions[torch.from_numpy(edge_dst)]\n",
    "                - positions[torch.from_numpy(edge_src)]\n",
    "                + torch.einsum('ni,nij->nj', torch.tensor(edge_shift, dtype=default_dtype), lattice[edge_batch]))\n",
    "\n",
    "    # compute edge lengths (rounded only for plotting purposes)\n",
    "    edge_len = np.around(edge_vec.norm(dim=1).numpy(), decimals=2)\n",
    "    \n",
    "    data = tg.data.Data(\n",
    "        pos=positions, lattice=lattice, symbol=symbols,\n",
    "        x=type_onehot[[type_encoding[specie] for specie in symbols]],\n",
    "        edge_index=torch.stack([torch.LongTensor(edge_src), torch.LongTensor(edge_dst)], dim=0),\n",
    "        edge_shift=torch.tensor(edge_shift, dtype=default_dtype),\n",
    "        edge_vec=edge_vec, edge_len=edge_len,\n",
    "        phdos=torch.from_numpy(entry.phdos).unsqueeze(0)\n",
    "    )\n",
    "    \n",
    "    return data\n",
    "\n",
    "r_max = 7. # cutoff radius\n",
    "df['data'] = df.progress_apply(lambda x: build_data(x, type_encoding, type_onehot, r_max), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6842dfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 12 # structure index in dataframe\n",
    "plot_example(df, i=i, label_edges=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394af1fc",
   "metadata": {},
   "source": [
    "### Training, validation, and testing datasets\n",
    "Split the data into training, validation, and testing datasets with balanced representation of different elements in each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb75584",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train/valid/test split\n",
    "idx_train, idx_valid, idx_test = train_valid_test_split(df, species, valid_size=.1, test_size=.1, seed=12, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8701141d",
   "metadata": {},
   "source": [
    "For use with the trained model provided, the indices of the training, validation, and test sets are loaded below. These indices were generated with a specific seed using the above `train_valid_test_split` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb03c3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train/valid/test indices\n",
    "with open('data/idx_train.txt', 'r') as f: idx_train = [int(i.split('\\n')[0]) for i in f.readlines()]\n",
    "with open('data/idx_valid.txt', 'r') as f: idx_valid = [int(i.split('\\n')[0]) for i in f.readlines()]\n",
    "with open('data/idx_test.txt', 'r') as f: idx_test = [int(i.split('\\n')[0]) for i in f.readlines()]\n",
    "\n",
    "# format dataloaders\n",
    "batch_size = 1\n",
    "dataloader_train = tg.loader.DataLoader(df.iloc[idx_train]['data'].values, batch_size=batch_size, shuffle=True)\n",
    "dataloader_valid = tg.loader.DataLoader(df.iloc[idx_valid]['data'].values, batch_size=batch_size)\n",
    "dataloader_test = tg.loader.DataLoader(df.iloc[idx_test]['data'].values, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013a4311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average number of neighbors\n",
    "def get_neighbors(df, idx):\n",
    "    n = []\n",
    "    for entry in df.iloc[idx].itertuples():\n",
    "        N = entry.data.pos.shape[0]\n",
    "        for i in range(N):\n",
    "            n.append(len((entry.data.edge_index[0] == i).nonzero()))\n",
    "    return np.array(n)\n",
    "\n",
    "n_train = get_neighbors(df, idx_train)\n",
    "n_valid = get_neighbors(df, idx_valid)\n",
    "n_test = get_neighbors(df, idx_test)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(5,4))\n",
    "b = 0.\n",
    "bins = 50\n",
    "for (d, c), n in zip(colors.items(), [n_train, n_valid, n_test]):\n",
    "    color = [int(c.lstrip('#')[i:i+2], 16)/255. for i in (0,2,4)]\n",
    "    y, bins, _, = ax.hist(n, bins=bins, fc=color+[0.7], ec=color, bottom=b, label=d)\n",
    "    b += y\n",
    "ax.set_xlabel('number of neighbors')\n",
    "ax.set_ylabel('number of examples')\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "print('average number of neighbors (train/valid/test):', n_train.mean(), '/', n_valid.mean(), '/', n_test.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81012f92",
   "metadata": {},
   "source": [
    "### Network architecture\n",
    "We build a model based on the `SimplePeriodicNetwork` described in the `e3nn` [Documentation](https://docs.e3nn.org/en/latest/guide/periodic_boundary_conditions.html), which applies equivariant convolutions to each atomic node and then takes an average over all nodes, normalizing the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8a44e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplePeriodicNetwork(SimpleNetwork):\n",
    "    def __init__(self, in_dim, em_dim, **kwargs):\n",
    "        # override the `pool_nodes` keyword to instead perform an averge over atom contributions    \n",
    "        self.pool = False\n",
    "        if kwargs['pool_nodes'] == True:\n",
    "            kwargs['pool_nodes'] = False\n",
    "            kwargs['num_nodes'] = 1.\n",
    "            self.pool = True\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # embed the mass-weighted one-hot encoding\n",
    "        self.em = nn.Linear(in_dim, em_dim)\n",
    "        \n",
    "    # overwrite the preprocess method of SimpleNetwork to adapt for periodic boundary data\n",
    "    def preprocess(self, data: Union[tg.data.Data, Dict[str, torch.Tensor]]) -> torch.Tensor:\n",
    "        if 'batch' in data:\n",
    "            batch = data['batch']\n",
    "        else:\n",
    "            batch = data['pos'].new_zeros(data['pos'].shape[0], dtype=torch.long)\n",
    "\n",
    "        edge_src = data['edge_index'][0]  # edge source\n",
    "        edge_dst = data['edge_index'][1]  # edge destination\n",
    "        edge_vec = data['edge_vec']\n",
    "        \n",
    "        return batch, data['x'], edge_src, edge_dst, edge_vec\n",
    "\n",
    "    def forward(self, data: Union[tg.data.Data, Dict[str, torch.Tensor]]) -> torch.Tensor:\n",
    "        data.x = F.relu(self.em(data.x))\n",
    "        output = super().forward(data)\n",
    "        output = torch.relu(output)\n",
    "        \n",
    "        # if pool_nodes was set to True, use scatter_mean to aggregate\n",
    "        if self.pool == True:\n",
    "            output = torch_scatter.scatter_mean(output, data.batch, dim=0)  # take mean over atoms per example\n",
    "        \n",
    "        maxima, _ = torch.max(output, dim=1)\n",
    "        output = output.div(maxima.unsqueeze(1))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d669bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dim = len(df.iloc[0]['phfreq'])\n",
    "em_dim = 64  \n",
    "\n",
    "model = SimplePeriodicNetwork(\n",
    "    in_dim=118,                     # dimension of one-hot encoding of atom type\n",
    "    em_dim=em_dim,                  # dimension of atom-type embedding \n",
    "    irreps_in=str(em_dim)+\"x0e\",    # em_dim scalars (L=0 and even parity) on each atom to represent atom type\n",
    "    irreps_out=str(out_dim)+\"x0e\",  # out_dim scalars (L=0 and even parity) to output\n",
    "    lmax=1,                         # maximum order of spherical harmonics\n",
    "    mul=32,                         # multiplicity of irreducible representations\n",
    "    layers=2,                       # number of nonlinearities (number of convolutions = layers + 1)\n",
    "    num_neighbors=n_train.mean(),   # scaling factor based on the typical number of neighbors\n",
    "    max_radius=r_max,               # cutoff radius for convolution\n",
    "    pool_nodes=True,\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85748807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize tensor products of the model\n",
    "visualize_layers(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e430815",
   "metadata": {},
   "source": [
    "### Training\n",
    "The model is trained using a mean-squared error loss function with an Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8ea728",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.AdamW(model.parameters(), lr=0.005, weight_decay=0.05)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(opt, gamma=0.96)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "loss_fn_mae = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b5d8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:6\" if torch.cuda.is_available() else \"cpu\"\n",
    "print('torch device:' , device)\n",
    "\n",
    "run_name = 'model_' + time.strftime(\"%y%m%d\", time.localtime())\n",
    "print(run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c3e2e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.pool = True\n",
    "train(model, opt, dataloader_train, dataloader_valid, loss_fn, loss_fn_mae, run_name,\n",
    "      max_iter=121, scheduler=scheduler, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00046bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model and plot its training history\n",
    "#run_name = 'model'\n",
    "\n",
    "history = torch.load(run_name + '.torch')['history']\n",
    "steps = [d['step'] + 1 for d in history]\n",
    "loss_train = [d['train']['loss'] for d in history]\n",
    "loss_valid = [d['valid']['loss'] for d in history]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "ax.plot(steps, loss_train, 'o-', label=\"Training\", color=colors['train'])\n",
    "ax.plot(steps, loss_valid, 'o-', label=\"Validation\", color=colors['valid'])\n",
    "ax.set_xlabel('epochs')\n",
    "ax.set_ylabel('loss')\n",
    "ax.legend(frameon=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a774a2c2",
   "metadata": {},
   "source": [
    "### Results\n",
    "We evaluate our model by visualizing the predicted and true DoS in each error quartile. We further compare the hidden features learned for each node to the partial DoS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9894d03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on all data\n",
    "model.load_state_dict(torch.load(run_name + '.torch')['state'])\n",
    "model.pool = True\n",
    "\n",
    "dataloader = tg.loader.DataLoader(df['data'].values, batch_size=64)\n",
    "df['mse'] = 0.\n",
    "df['phdos_pred'] = np.empty((len(df), 0)).tolist()\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    i0 = 0\n",
    "    for i, d in tqdm(enumerate(dataloader), total=len(dataloader), bar_format=bar_format):\n",
    "        d.to(device)\n",
    "        output = model(d)\n",
    "        loss = F.mse_loss(output, d.phdos, reduction='none').mean(dim=-1).cpu().numpy()\n",
    "        df.loc[i0:i0 + len(d.phdos) - 1, 'phdos_pred'] = [[k] for k in output.cpu().numpy()]\n",
    "        df.loc[i0:i0 + len(d.phdos) - 1, 'mse'] = loss\n",
    "        i0 += len(d.phdos)\n",
    "        \n",
    "df['phdos_pred'] = df['phdos_pred'].map(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b42f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(df, idx_train, 'Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd870c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(df, idx_valid, 'Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19baf089",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(df, idx_test, 'Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea21f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare to partial DoS\n",
    "model.load_state_dict(torch.load(run_name + '.torch')['state'])\n",
    "model.pool = False\n",
    "\n",
    "# plot example predicted and true partial dos\n",
    "plot_partials(model, df, idx_train, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dadbab7",
   "metadata": {},
   "source": [
    "### Alloys\n",
    "The current framework extends easily to the representation of alloy structures. As an example, we will predict the phonon DoS of the Mg<sub>3</sub>(Bi,Sb)<sub>2</sub> system, incrementally varying the relative fractions of Bi and Sb. Note that both parent compounds, Mg<sub>3</sub>Sb<sub>2</sub> and Mg<sub>3</sub>Bi<sub>2</sub>, are present in our training data. We will check the validity by comparing the predicted and calculated phonon DoS of Mg<sub>3</sub>Bi<sub>1.5</sub>Sb<sub>0.5</sub>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac684344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load calculated alloy example\n",
    "df_alloy, _ = load_data('data/data_alloy.csv')\n",
    "df_alloy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b05950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indices of parent structures\n",
    "idx_Mg3Sb2 = df.loc[df['mp_id'] == 'mp-2646'].index.to_numpy()[0]\n",
    "idx_Mg3Bi2 = df.loc[df['mp_id'] == 'mp-569018'].index.to_numpy()[0]\n",
    "print(f'index of Mg3Sb2: {idx_Mg3Sb2}', f'\\nindex of Mg3Bi2: {idx_Mg3Bi2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa217c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate atomic positions and lattice constants\n",
    "# 2-hot encode the atomic mass, weighted by the fraction of each species\n",
    "data_alloy = []\n",
    "x_Bi = np.linspace(0.01, 0.99, 99)\n",
    "\n",
    "for i, p in tqdm(enumerate(x_Bi), total=len(x_Bi), bar_format=bar_format):\n",
    "    symbols = df['data'][idx_Mg3Bi2].symbol.copy()\n",
    "    positions = torch.lerp(df['data'][idx_Mg3Sb2].pos.clone(), df['data'][idx_Mg3Bi2].pos.clone(), p)\n",
    "    lattice = torch.lerp(df['data'][idx_Mg3Sb2].lattice.clone(), df['data'][idx_Mg3Bi2].lattice.clone(), p)\n",
    "\n",
    "    # edge_src and edge_dst are the indices of the central and neighboring atom, respectively\n",
    "    # edge_shift indicates whether the neighbors are in different images or copies of the unit cell\n",
    "    struct = df.iloc[idx_Mg3Bi2].structure.copy()\n",
    "    struct.positions = positions.numpy().copy()\n",
    "    struct.cell = lattice.numpy().squeeze().copy()\n",
    "    edge_src, edge_dst, edge_shift = neighbor_list(\"ijS\", a=struct, cutoff=r_max/2., self_interaction=True)\n",
    "    \n",
    "    # compute the relative distances and unit cell shifts from periodic boundaries\n",
    "    edge_batch = positions.new_zeros(positions.shape[0], dtype=torch.long)[torch.from_numpy(edge_src)]\n",
    "    edge_vec = (positions[torch.from_numpy(edge_dst)]\n",
    "                - positions[torch.from_numpy(edge_src)]\n",
    "                + torch.einsum('ni,nij->nj', torch.tensor(edge_shift, dtype=default_dtype), lattice[edge_batch]))\n",
    "\n",
    "    # compute edge lengths (rounded only for plotting purposes)\n",
    "    edge_len = np.around(edge_vec.norm(dim=1).numpy(), decimals=2)\n",
    "    \n",
    "    data_alloy.append(\n",
    "            tg.data.Data(\n",
    "            pos=positions, \n",
    "            lattice=lattice, \n",
    "            symbol=symbols,\n",
    "            x=torch.lerp(df['data'][idx_Mg3Sb2].x, df['data'][idx_Mg3Bi2].x, p),\n",
    "            edge_index=torch.stack([torch.LongTensor(edge_src), torch.LongTensor(edge_dst)], dim=0),\n",
    "            edge_shift=torch.tensor(edge_shift, dtype=default_dtype),\n",
    "            edge_vec=edge_vec, edge_len=edge_len,\n",
    "            phdos=df['data'][idx_Mg3Bi2].phdos.clone()\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e59c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on all alloy structures\n",
    "model.load_state_dict(torch.load(run_name + '.torch')['state'])\n",
    "model.pool = True\n",
    "\n",
    "dataloader = tg.loader.DataLoader([df.iloc[idx_Mg3Sb2]['data']] + data_alloy + [df.iloc[idx_Mg3Bi2]['data']],\n",
    "                                  batch_size=32)\n",
    "\n",
    "output = np.zeros((len(data_alloy) + 2, len(df_alloy['phdos'][0])))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    i0 = 0\n",
    "    for i, d in tqdm(enumerate(dataloader), total=len(dataloader), bar_format=bar_format):\n",
    "        d.to(device)\n",
    "        output[i0:i0 + len(d.phdos),:] = model(d).cpu().numpy()\n",
    "        i0 += len(d.phdos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee5de9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot predictions, and compare with calculated result for selected compound\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,6), gridspec_kw={'width_ratios': [1,2]})\n",
    "color = cmap(np.linspace(0, 1, len(output)))\n",
    "f = df_alloy['phfreq'][0]\n",
    "\n",
    "# waterfall plot of alloy predictions\n",
    "s = 2./len(x_Bi)\n",
    "for i in range(len(output)):\n",
    "    ax1.plot(f, output[i]/output[i].max() + i*s, c=color[i])\n",
    "ax1.set_yticklabels([])\n",
    "ax1.set_xlabel('$Frequency\\ (cm^{-1})$')\n",
    "ax1.set_ylabel('$Intensity$')\n",
    "\n",
    "sm = mpl.cm.ScalarMappable(cmap=cmap)\n",
    "sm.set_array([])\n",
    "cax = inset_axes(ax1, width=\"40%\", height=\"4%\", loc=3, bbox_to_anchor=(0.5,0.9,1,1), bbox_transform=ax1.transAxes) \n",
    "cbar = fig.colorbar(sm, cax=cax, aspect=16, orientation='horizontal', pad=-0.1)\n",
    "cbar.ax.set_xlabel('$x_{Bi}$', fontsize=16, labelpad=-5)\n",
    "    \n",
    "# comparison to calculation\n",
    "p = x_Bi.tolist().index(0.75)\n",
    "ax2.remove()\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "\n",
    "# plot calculations\n",
    "ax2.plot(f, [0.75]*len(f), df_alloy['phdos'][0], lw=1.5, c='black', label='Calculated')\n",
    "ax2.plot(f, [0]*len(f), df.iloc[idx_Mg3Sb2]['phdos'], lw=1.5, c='black')\n",
    "ax2.plot(f, [1]*len(f), df.iloc[idx_Mg3Bi2]['phdos'], lw=1.5, c='black')\n",
    "\n",
    "# plot predictions\n",
    "ax2.plot(f, [0.75]*len(f), output[p]/output[p].max(), lw=2, c=palette[1], label='Predicted (alloy)')\n",
    "ax2.plot(f, [0]*len(f), output[0]/output[0].max(), lw=2, c=palette[0], label='Predicted (pure)')\n",
    "ax2.plot(f, [1]*len(f), output[-1]/output[-1].max(), lw=2, c=palette[0])\n",
    "\n",
    "ax2.view_init(elev=20, azim=-50)\n",
    "ax2.w_xaxis.set_pane_color((1., 1., 1., 1.))\n",
    "ax2.w_yaxis.set_pane_color((1., 1., 1., 1.))\n",
    "ax2.w_zaxis.set_pane_color((0.9, 0.9, 0.9, 1.))\n",
    "ax2.grid(False)\n",
    "ax2.w_xaxis.line.set_color('dimgray'); ax2.w_yaxis.line.set_color('dimgray'); ax2.w_zaxis.line.set_color('dimgray')\n",
    "    \n",
    "ax2.set_xlabel('$Frequency\\ (cm^{-1})$', labelpad=14)\n",
    "ax2.set_ylabel('$x_{Bi}$', labelpad=10)\n",
    "ax2.set_zlabel('$Intensity$', labelpad=10)\n",
    "ax2.legend(frameon=False, bbox_to_anchor=(0.9,0.4), bbox_transform=fig.transFigure);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4282187",
   "metadata": {},
   "source": [
    "### Visualization of intermediate features\n",
    "We can visualize the intermediate features on each node projected onto the basis of spherical harmonics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c735f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = next(iter(dataloader_train))\n",
    "specie = d.symbol[0]\n",
    "sts, st_feats = get_middle_feats(d, model, normalize=True)\n",
    "\n",
    "for sts_idx in range(len(sts)):\n",
    "    traces, traces_species = plotly_surface(sts[sts_idx], st_feats[sts_idx].detach().cpu(), centers=d.pos.cpu(),\n",
    "                                            res=20, radius=True, species=specie)\n",
    "    fig_html = plot_orbitals(traces, traces_species, title_str=f'feature: {str(sts[sts_idx])}')\n",
    "    \n",
    "    with open(f'feature_{str(sts[sts_idx])}.html', 'w') as f:\n",
    "        f.write(fig_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ade6e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
